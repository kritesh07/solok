#!/bin/bash
short_host=`hostname -s`
long_host=`hostname`
IP="`wget -q -O - http://169.254.169.254/latest/meta-data/public-ipv4`"
PVT_IP="Hostname=`wget -q -O - http://169.254.169.254/latest/meta-data/local-ipv4`"
s3bucket=s3clbackups

export path1=/data01/backups/db_backups
export path2=/s3backups/"$short_host"_$IP/db_backups/
export path3=/s3backups/"$short_host"_$IP/monthly_backups/
date1=`date +%y%m%d_%H%M%S`
/usr/bin/find $path1/* -type d -mtime +2 -exec rm -r {} \; 2> /dev/null
cd $path1/
mkdir $date1
USER="collectiveadmin"
PASSWORD="bzrcyUCXre1bW6f71sC6V6ei6"
OUTPUTDIR="$path1/$date1"
MYSQLDUMP="/usr/bin/mysqldump"
MYSQL="/usr/bin/mysql"
HOST="devdb.collectivelaboratories.com"

databases=`$MYSQL --user=$USER --password=$PASSWORD --host=$HOST \
         -e "SHOW DATABASES;" | tr -d "| " | grep -v Database`
echo "` for db in $databases; do
                echo $db

        if [ "$db" = "performance_schema" ] ; then
                $MYSQLDUMP --force --opt --single-transaction --lock-tables=false --skip-events --user=$USER --password=$PASSWORD --host=$HOST --routines $db | gzip > "$OUTPUTDIR/$db.sql.gz"
        else

                $MYSQLDUMP --force --opt --single-transaction --lock-tables=false --events --user=$USER --password=$PASSWORD --host=$HOST --routines $db | gzip > "$OUTPUTDIR/$db.sql.gz"
        fi
done `"

if [ $? -eq 0 ] ; then
        cp -r $path1/$date1 $path2/
fi

if [ $sysdate -eq 1 ] ; then
        cp -r $path1/$date1 $path3/
fi

rm -r /data01/tmp/$s3bucket/"$short_host"_$IP/db_backups/*
rm -r /data01/tmp/$s3bucket/"$short_host"_$IP/monthly_backups/*
/home/som/monitor.sh 99 | tee /home/som/backup_report >> /home/monthly_backup_report #to create a backup report in /home/som/backup_report file-
cat /home/som/backup_report | mail -s "backup_report of $long_host ($IP) " -r $short_host@collectivelaboratoreis.com support@mitainfotech.com
root@devserver:/data01/backups/scripts# cat web_backup.sh 
#!/bin/bash
HOST="localhost"
short_host=`hostname -s`
long_host=`hostname`
IP="`wget -q -O - http://169.254.169.254/latest/meta-data/public-ipv4`"
PVT_IP="Hostname=`wget -q -O - http://169.254.169.254/latest/meta-data/local-ipv4`"
s3bucket=s3clbackups

export path1=/data01/backups/web_backups
export path2=/s3backups/"$short_host"_$IP/web_backups
date1=`date +%y%m%d_%H%M%S`


/usr/bin/find $path1/* -type d -mtime +2 -exec rm -r {} \; 2> /dev/null
mkdir $path1/$date1
cd /
cp -r /var/www/html $path1/
cd $path1/html
for i in */; do /bin/tar -zcvf "$path1/$date1/${i%/}.tar.gz" "$i"; done
if [ $? -eq 0 ] ; then 
                rm -r $path1/html
fi
cd /
cp -r $path1/$date1 $path2/
rm -r /data01/tmp/$s3bucket/"$short_host"_$IP/web_backups/*

/home/som/monitor.sh 99 | tee /home/som/backup_report >> /home/monthly_backup_report
cat /home/som/backup_report | mail -s "backup_report of $long_host ($IP) " -r $short_host@collectivelaboratories.com support@mitainfotech.com

if [ `date +%d` -eq '01' ] ; then
        mv /home/som/monthly_backup_report /home/som/"$short_host"_$IP_Backup_Report_`date +%B_%G --date="-1 day"`
fi
sh -c "sync; echo 3 > /proc/sys/vm/drop_caches"